# app.py
import streamlit as st
import pandas as pd
import numpy as np
from ta.momentum import RSIIndicator
from ta.trend import MACD, SMAIndicator, EMAIndicator
import joblib
import os

# --- PAGE CONFIGURATION (MUST BE THE FIRST STREAMLIT COMMAND) ---
st.set_page_config(page_title="BTC Fiyat YÃ¶nÃ¼ Tahmini", layout="wide")

# --- Configuration ---
MODEL_PATH = "svm_rfe_model.pkl"
SCALER_PATH = "scaler.pkl"
FEATURES_PATH = "rfe_selected_features.pkl"
# YENÄ°: Scaler iÃ§in doÄŸru sÃ¼tun sÄ±rasÄ±nÄ±n yolu
SCALER_COLUMNS_PATH = "features_columns_for_scaler.pkl"
HISTORICAL_DATA_PATH = "C:/Users/yildi/OneDrive/Desktop/projeCrypto/btc_verisi.csv" # Gerekirse gÃ¼ncelleyin
REQUIRED_HISTORICAL_DAYS = 40 # Ä°ndikatÃ¶r hesaplama baÄŸlamÄ± iÃ§in

# --- 1. Load Saved Artifacts ---
@st.cache_resource
def load_model_assets():
    paths = {
        "Model": MODEL_PATH,
        "Scaler": SCALER_PATH,
        "RFE Ã–zellikleri": FEATURES_PATH,
        "Scaler SÃ¼tunlarÄ±": SCALER_COLUMNS_PATH
    }
    loaded_assets = {}
    all_exist = True
    for name, path in paths.items():
        if not os.path.exists(path):
            st.error(f"{name} dosyasÄ± bulunamadÄ±: {path}")
            all_exist = False
    if not all_exist:
        return None

    try:
        loaded_assets["model"] = joblib.load(MODEL_PATH)
        loaded_assets["scaler"] = joblib.load(SCALER_PATH)
        loaded_assets["rfe_features_list"] = joblib.load(FEATURES_PATH)
        loaded_assets["scaler_columns_list"] = joblib.load(SCALER_COLUMNS_PATH)
        return loaded_assets
    except Exception as e:
        st.error(f"Model varlÄ±klarÄ± yÃ¼klenirken hata: {e}")
        return None

@st.cache_data # Veri yÃ¼klemeyi Ã¶nbelleÄŸe al
def load_historical_data(file_path):
    if not os.path.exists(file_path):
        st.error(f"GeÃ§miÅŸ veri dosyasÄ± bulunamadÄ±: {file_path}")
        return None
    try:
        # Ä°ndikatÃ¶r hesaplama baÄŸlamÄ± iÃ§in sadece Open, Close, Volume gerekli
        df = pd.read_csv(file_path, usecols=['Open', 'Close', 'Volume'])
        if len(df) < REQUIRED_HISTORICAL_DAYS:
            st.warning(f"GeÃ§miÅŸ veri dosyasÄ±nda yetersiz satÄ±r var. En az {REQUIRED_HISTORICAL_DAYS} gÃ¼n gerekli.")
            # Yine de devam etmeye izin ver, ancak daha sonra hata verebilir
        return df
    except Exception as e:
        st.error(f"GeÃ§miÅŸ veri yÃ¼klenirken hata oluÅŸtu: {e}")
        return None

# --- 2. Feature Engineering Function ---
def calculate_technical_indicators(df_input):
    df = df_input.copy()
    if 'Close' not in df.columns:
        raise ValueError("DataFrame indikatÃ¶r hesaplamasÄ± iÃ§in 'Close' sÃ¼tununu iÃ§ermelidir.")
    df['Close'] = pd.to_numeric(df['Close'], errors='coerce')
    if df['Close'].isnull().any(): # DÃ¶nÃ¼ÅŸÃ¼m sonrasÄ± kontrol et
        raise ValueError("Close sÃ¼tunu dÃ¶nÃ¼ÅŸtÃ¼rme sonrasÄ± sayÄ±sal olmayan deÄŸerler iÃ§eriyor.")

    # RSI
    rsi_indicator = RSIIndicator(close=df["Close"], window=14)
    df["RSI"] = rsi_indicator.rsi()

    # MACD
    macd_indicator = MACD(close=df["Close"])
    df["MACD"] = macd_indicator.macd()
    df["Signal"] = macd_indicator.macd_signal() # MACD Sinyal HattÄ±

    # SMA20
    sma_indicator = SMAIndicator(close=df["Close"], window=20)
    df["SMA20"] = sma_indicator.sma_indicator()

    # EMA20
    ema_indicator = EMAIndicator(close=df["Close"], window=20)
    df["EMA20"] = ema_indicator.ema_indicator()

    return df

# --- VarlÄ±klarÄ± yÃ¼kle (set_page_config ve fonksiyon tanÄ±mlamalarÄ±ndan sonra) ---
assets = load_model_assets()
historical_data_full = load_historical_data(HISTORICAL_DATA_PATH)

# --- 3. Streamlit UI ---
st.title("Bitcoin (BTC/USD) Fiyat YÃ¶nÃ¼ Tahmini")

if assets is None or historical_data_full is None:
    st.error("Uygulama baÅŸlatÄ±lamadÄ±. LÃ¼tfen yukarÄ±daki hata mesajlarÄ±nÄ± kontrol edin ve gerekli dosyalarÄ±n mevcut olduÄŸundan emin olun.")
    st.stop() # Hata varsa uygulamayÄ± durdur

model = assets["model"]
scaler = assets["scaler"]
RFE_SELECTED_FEATURES = assets["rfe_features_list"]
SCALER_INPUT_COLUMNS = assets["scaler_columns_list"] # Dosyadan yÃ¼klenen liste

st.sidebar.header("GÃ¼ncel GÃ¼nÃ¼n Verilerini Girin")
st.sidebar.markdown("LÃ¼tfen tahmin yapmak istediÄŸiniz gÃ¼nÃ¼n AÃ§Ä±lÄ±ÅŸ (Open), KapanÄ±ÅŸ (Close) ve Hacim (Volume) deÄŸerlerini girin.")

# GerÃ§ekÃ§i varsayÄ±lan deÄŸerler
default_open = historical_data_full['Open'].iloc[-1] if not historical_data_full.empty else 40000.0
default_close = historical_data_full['Close'].iloc[-1] if not historical_data_full.empty else 40500.0
default_volume = historical_data_full['Volume'].iloc[-1] if not historical_data_full.empty else 50000000000.0

current_open = st.sidebar.number_input("BugÃ¼nkÃ¼ AÃ§Ä±lÄ±ÅŸ (Open)", value=float(default_open), step=100.0, format="%.2f")
current_close = st.sidebar.number_input("BugÃ¼nkÃ¼ KapanÄ±ÅŸ (Close)", value=float(default_close), step=100.0, format="%.2f")
current_volume = st.sidebar.number_input("BugÃ¼nkÃ¼ Hacim (Volume)", value=float(default_volume), step=1000000.0, format="%.0f")

if st.sidebar.button("Tahmin Et", type="primary"):
    if len(historical_data_full) < REQUIRED_HISTORICAL_DAYS -1 :
         st.error(f"Tahmin iÃ§in yetersiz geÃ§miÅŸ veri. En az {REQUIRED_HISTORICAL_DAYS-1} geÃ§miÅŸ gÃ¼n verisi gereklidir.")
    else:
        try:
            # BaÄŸlam iÃ§in geÃ§miÅŸ verinin son N-1 gÃ¼nÃ¼nÃ¼ al
            recent_history = historical_data_full[['Open', 'Close', 'Volume']].iloc[-(REQUIRED_HISTORICAL_DAYS - 1):].copy()

            # Mevcut gÃ¼nÃ¼n verileri iÃ§in bir DataFrame oluÅŸtur
            current_data_dict = {
                'Open': [current_open],
                'Close': [current_close],
                'Volume': [current_volume]
            }
            current_df_row = pd.DataFrame(current_data_dict)

            # GeÃ§miÅŸ verileri mevcut gÃ¼nle birleÅŸtir
            combined_df = pd.concat([recent_history, current_df_row], ignore_index=True)

            # Ä°ndikatÃ¶rleri hesapla
            df_with_indicators = calculate_technical_indicators(combined_df)

            # Son satÄ±rÄ± al (tÃ¼m indikatÃ¶rlerle mevcut gÃ¼nÃ¼n verileri)
            current_features_for_prediction = df_with_indicators.iloc[-1:].copy() # DataFrame olarak kalsÄ±n

            # SCALER_INPUT_COLUMNS artÄ±k dosyadan yÃ¼kleniyor.
            
            # Ã–lÃ§ekleme iÃ§in tÃ¼m gerekli sÃ¼tunlarÄ±n mevcut olduÄŸundan emin ol
            missing_cols = [col for col in SCALER_INPUT_COLUMNS if col not in current_features_for_prediction.columns]
            if missing_cols:
                st.error(f"Ä°ndikatÃ¶r hesaplamasÄ± sonrasÄ± beklenen sÃ¼tunlar eksik: {', '.join(missing_cols)}. "
                         f"Beklenen sÃ¼tunlar: {SCALER_INPUT_COLUMNS}. "
                         f"Mevcut sÃ¼tunlar: {current_features_for_prediction.columns.tolist()}")
            # current_features_for_prediction'dan SCALER_INPUT_COLUMNS kullanarak bir alt kÃ¼me oluÅŸturmadan Ã¶nce NaN kontrolÃ¼ yap
            elif current_features_for_prediction.isnull().values.any(): # Ä°ndikatÃ¶r hesaplamasÄ±ndan sonra NaN var mÄ± kontrol et
                 st.error("Ä°ndikatÃ¶r hesaplamasÄ± sonucu NaN deÄŸerler oluÅŸtu. Bu genellikle yetersiz geÃ§miÅŸ veriden kaynaklanÄ±r. LÃ¼tfen verileri kontrol edin.")
                 st.write("Ä°ndikatÃ¶rlÃ¼ son satÄ±r (NaN iÃ§eren):")
                 st.dataframe(current_features_for_prediction)

            elif current_features_for_prediction[SCALER_INPUT_COLUMNS].isnull().values.any(): # Daha saÄŸlam NaN kontrolÃ¼
                st.error("Teknik indikatÃ¶rler hesaplanÄ±rken bir sorun oluÅŸtu (NaN deÄŸerler). Bu genellikle yetersiz geÃ§miÅŸ veriden veya girilen hatalÄ± deÄŸerlerden kaynaklanÄ±r.")
                st.write("Hesaplanan son satÄ±r (indikatÃ¶rler dahil, Ã¶lÃ§ekleme Ã¶ncesi):")
                st.dataframe(current_features_for_prediction[SCALER_INPUT_COLUMNS])
            else:
                # Ã–zellikleri scaler'Ä±n beklediÄŸi sÄ±raya gÃ¶re dÃ¼zenle
                to_scale_df = current_features_for_prediction[SCALER_INPUT_COLUMNS]
                
                # Ã–zellikleri Ã¶lÃ§ekle
                scaled_features_array = scaler.transform(to_scale_df)
                # Ã–lÃ§eklenmiÅŸ DataFrame'i de aynÄ± sÃ¼tun isimleri ve sÄ±rasÄ±yla oluÅŸtur
                scaled_features_df = pd.DataFrame(scaled_features_array, columns=SCALER_INPUT_COLUMNS, index=to_scale_df.index)
                
                # RFE ile seÃ§ilen Ã¶zellikleri bu doÄŸru sÄ±ralanmÄ±ÅŸ ve Ã¶lÃ§eklenmiÅŸ DataFrame'den al
                final_features_for_model = scaled_features_df[RFE_SELECTED_FEATURES]

                # Tahmin yap
                prediction = model.predict(final_features_for_model)
                
                # Sonucu gÃ¶ster
                st.subheader("Tahmin Sonucu")
                col1, col2 = st.columns([1,3])
                with col1:
                    if prediction[0] == 1:
                        st.image("https://emojigraph.org/media/apple/chart-increasing_1f4c8.png", width=100)
                    else:
                        st.image("https://emojigraph.org/media/apple/chart-decreasing_1f4c9.png", width=100)
                with col2:
                    if prediction[0] == 1:
                        st.success("ðŸ“ˆ **YÃœKSELÄ°Åž** bekleniyor.")
                        st.markdown("Tahminimiz, yarÄ±nki Bitcoin kapanÄ±ÅŸ fiyatÄ±nÄ±n bugÃ¼nkÃ¼ kapanÄ±ÅŸ fiyatÄ±ndan **daha yÃ¼ksek** olacaÄŸÄ± yÃ¶nÃ¼ndedir.")
                    else:
                        st.error("ðŸ“‰ **DÃœÅžÃœÅž** bekleniyor.")
                        st.markdown("Tahminimiz, yarÄ±nki Bitcoin kapanÄ±ÅŸ fiyatÄ±nÄ±n bugÃ¼nkÃ¼ kapanÄ±ÅŸ fiyatÄ±ndan **daha dÃ¼ÅŸÃ¼k** olacaÄŸÄ± yÃ¶nÃ¼ndedir.")

                with st.expander("Detaylar: Modele Giren Veriler"):
                    st.markdown("##### Ham Girilen Veriler (BugÃ¼n):")
                    st.dataframe(current_df_row.style.format({"Open": "{:.2f}", "Close": "{:.2f}", "Volume": "{:.0f}"}))
                    st.markdown(f"##### {REQUIRED_HISTORICAL_DAYS} GÃ¼nlÃ¼k Veri Ãœzerinden Hesaplanan Ä°ndikatÃ¶rler (BugÃ¼n Ä°Ã§in, Ã–lÃ§ekleme Ã–ncesi):")
                    st.dataframe(to_scale_df.style.format("{:.2f}"))
                    st.markdown("##### Ã–lÃ§eklenmiÅŸ ve Model Ä°Ã§in SeÃ§ilmiÅŸ Ã–zellikler:")
                    st.dataframe(final_features_for_model.style.format("{:.4f}"))
                    st.caption(f"Modelin kullandÄ±ÄŸÄ± Ã¶zellikler: ` {', '.join(RFE_SELECTED_FEATURES)} `")

        except ValueError as ve:
            st.error(f"Veri hatasÄ±: {ve}")
        except Exception as e:
            st.error(f"Tahmin sÄ±rasÄ±nda beklenmedik bir hata oluÅŸtu: {e}")
            st.error("LÃ¼tfen girdiÄŸiniz deÄŸerleri ve geÃ§miÅŸ veri dosyasÄ±nÄ±n bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ kontrol edin.")
            import traceback
            st.text(traceback.format_exc()) # HatanÄ±n tam dÃ¶kÃ¼mÃ¼nÃ¼ gÃ¶rmek iÃ§in

st.sidebar.markdown("---")
st.sidebar.caption("Bu uygulama demo amaÃ§lÄ±dÄ±r ve yatÄ±rÄ±m tavsiyesi deÄŸildir.")

# --- Ä°steÄŸe baÄŸlÄ±: BazÄ± geÃ§miÅŸ veri baÄŸlamÄ±nÄ± gÃ¶ster ---
if not historical_data_full.empty:
    st.markdown("---")
    st.subheader("GeÃ§miÅŸ Veri Ã–rneÄŸi (Son 5 GÃ¼n)")
    st.dataframe(historical_data_full[['Open', 'Close', 'Volume']].tail().reset_index(drop=True).style.format({"Open": "{:.2f}", "Close": "{:.2f}", "Volume": "{:.0f}"}))